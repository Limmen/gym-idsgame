# V0 Experiments

tabular_q_learning_vs_random_defense-v0: training/v0/random_defense/tabular_q_learning/run.py training/v0/random_defense/tabular_q_learning/run.sh
	cd training/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v0: training/v0/minimal_defense/tabular_q_learning/run.py training/v0/minimal_defense/tabular_q_learning/run.sh
	cd training/v0/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_q_learning-v0: training/v0/random_attack/tabular_q_learning/run.py training/v0/random_attack/tabular_q_learning/run.sh
	cd training/v0/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v0: training/v0/maximal_attack/tabular_q_learning/run.py training/v0/maximal_attack/tabular_q_learning/run.sh
	cd training/v0/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v0: training/v0/two_agents/tabular_q_learning/run.py training/v0/two_agents/tabular_q_learning/run.sh
	cd training/v0/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_tabular_random_defense-v0: training/v0/random_defense/dqn/run.py training/v0/random_defense/dqn/run.sh
	cd training/v0/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v0: training/v0/minimal_defense/dqn/run.py training/v0/minimal_defense/dqn/run.sh
	cd training/v0/minimal_defense/dqn/ && $(MAKE) run

maximal_attack_vs_dqn-v0: training/v0/maximal_attack/dqn/run.py training/v0/maximal_attack/dqn/run.sh
	cd training/v0/maximal_attack/dqn/ && $(MAKE) run

random_attack_vs_dqn-v0: training/v0/random_attack/dqn/run.py training/v0/random_attack/dqn/run.sh
	cd training/v0/random_attack/dqn/ && $(MAKE) run

random_vs_random-v0: simulations/v0/random_vs_random/run.py simulations/v0/random_vs_random/run.sh
	cd simulations/v0/random_vs_random/ && $(MAKE) run

random_vs_defend_minimal-v0: simulations/v0/random_vs_defend_minimal/run.py simulations/v0/random_vs_defend_minimal/run.sh
	cd simulations/v0/random_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_defend_minimal-v0: simulations/v0/attack_maximal_vs_defend_minimal/run.py simulations/v0/attack_maximal_vs_defend_minimal/run.sh
	cd simulations/v0/attack_maximal_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_random-v0: simulations/v0/attack_maximal_vs_random/run.py simulations/v0/attack_maximal_vs_random/run.sh
	cd simulations/v0/attack_maximal_vs_random/ && $(MAKE) run

tabular_q_agent_vs_random-v0: simulations/v0/tabular_q_agent_vs_random/run.py simulations/v0/tabular_q_agent_vs_random/run.sh
	cd simulations/v0/tabular_q_agent_vs_random/ && $(MAKE) run

random_vs_tabular_q_agent-v0: simulations/v0/random_Vs_tabular_q_agent/run.py simulations/v0/random_vs_tabular_q_agent/run.sh
	cd simulations/v0/random_vs_tabular_q_agent/ && $(MAKE) run

v0: tabular_q_learning_vs_random_defense-v0 random_vs_random-v0 random_vs_defend_minimal-v0
v0: attack_maximal_vs_defend_minimal-v0 attack_maximal_vs_random-v0 random_attack_vs_tabular_q_learning-v0
v0: maximal_attack_vs_tabular_q_learning-v0 tabular_q_agent_vs_random-v0
v0: tabular_q_learning_vs_tabular_q_learning-v0 dqn_vs_tabular_random_defense-v0
v0: dqn_vs_minimal_defense-v0 maximal_attack_vs_dqn-v0 random_attack_vs_dqn-v0

# V1 Experiments

tabular_q_learning_vs_random_defense-v1: training/v1/random_defense/tabular_q_learning/run.py training/v1/random_defense/tabular_q_learning/run.sh
	cd training/v1/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v1: training/v1/minimal_defense/tabular_q_learning/run.py training/v1/minimal_defense/tabular_q_learning/run.sh
	cd training/v1/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_fq_learning-v1: training/v1/random_attack/tabular_q_learning/run.py training/v1/random_attack/tabular_q_learning/run.sh
	cd training/v1/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v1: training/v1/maximal_attack/tabular_q_learning/run.py training/v1/maximal_attack/tabular_q_learning/run.sh
	cd training/v1/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v1: training/v1/two_agents/tabular_q_learning/run.py training/v1/two_agents/tabular_q_learning/run.sh
	cd training/v1/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_random_defense-v1: training/v1/random_defense/dqn/run.py training/v1/random_defense/dqn/run.sh
	cd training/v1/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v1: training/v1/minimal_defense/dqn/run.py training/v1/minimal_defense/dqn/run.sh
	cd training/v1/minimal_defense/dqn/ && $(MAKE) run

random_vs_random-v1: simulations/v1/random_vs_random/run.py simulations/v1/random_vs_random/run.sh
	cd simulations/v1/random_vs_random/ && $(MAKE) run

random_vs_defend_minimal-v1: simulations/v1/random_vs_defend_minimal/run.py simulations/v1/random_vs_defend_minimal/run.sh
	cd simulations/v1/random_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_defend_minimal-v1: simulations/v1/attack_maximal_vs_defend_minimal/run.py simulations/v1/attack_maximal_vs_defend_minimal/run.sh
	cd simulations/v1/attack_maximal_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_random-v1: simulations/v1/attack_maximal_vs_random/run.py simulations/v1/attack_maximal_vs_random/run.sh
	cd simulations/v1/attack_maximal_vs_random/ && $(MAKE) run

v1: tabular_q_learning_vs_random_defense-v1 random_vs_random-v1 random_vs_defend_minimal-v1
v1: attack_maximal_vs_defend_minimal-v1 attack_maximal_vs_random-v1 random_attack_vs_tabular_q_learning-v1
v1: maximal_attack_vs_tabular_q_learning-v1 tabular_q_learning_vs_tabular_q_learning-v1
v1: dqn_vs_random_defense-v1 dqn_vs_minimal_defense-v1

# V2 Experiments

tabular_q_learning_vs_random_defense-v2: training/v2/random_defense/tabular_q_learning/run.py training/v2/random_defense/tabular_q_learning/run.sh
	cd training/v2/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v2: training/v2/minimal_defense/tabular_q_learning/run.py training/v2/minimal_defense/tabular_q_learning/run.sh
	cd training/v2/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_fq_learning-v2: training/v2/random_attack/tabular_q_learning/run.py
	cd training/v2/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v2: training/v2/maximal_attack/tabular_q_learning/run.py training/v2/maximal_attack/tabular_q_learning/run.sh
	cd training/v2/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v2: training/v2/two_agents/tabular_q_learning/run.py training/v2/two_agents/tabular_q_learning/run.sh
	cd training/v2/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_random_defense-v2: training/v2/random_defense/dqn/run.py training/v2/random_defense/dqn/run.sh
	cd training/v2/random_defense/dqn/ && $(MAKE) run

dqn_vs_tabular_minimal_defense-v2: training/v2/minimal_defense/dqn/run.py training/v2/minimal_defense/dqn/run.sh
	cd training/v2/minimal_defense/dqn/ && $(MAKE) run

random_vs_random-v2: simulations/v2/random_vs_random/run.py simulations/v2/random_vs_random/run.sh
	cd simulations/v2/random_vs_random/ && $(MAKE) run

random_vs_defend_minimal-v2: simulations/v2/random_vs_defend_minimal/run.py simulations/v2/random_vs_defend_minimal/run.sh
	cd simulations/v2/random_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_defend_minimal-v2: simulations/v2/attack_maximal_vs_defend_minimal/run.py simulations/v2/attack_maximal_vs_defend_minimal/run.sh
	cd simulations/v2/attack_maximal_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_random-v2: simulations/v2/attack_maximal_vs_random/run.py simulations/v2/attack_maximal_vs_random/run.sh
	cd simulations/v2/attack_maximal_vs_random/ && $(MAKE) run

v2: tabular_q_learning_vs_random_defense-v2 tabular_q_learning_vs_minimal_defense-v2
v2: random_attack_vs_tabular_fq_learning-v2 maximal_attack_vs_tabular_q_learning-v2
v2: random_vs_random-v2 random_vs_defend_minimal-v2 attack_maximal_vs_defend_minimal-v2
v2: attack_maximal_vs_random-v2 tabular_q_learning_vs_tabular_q_learning-v2
v2: dqn_vs_random_defense-v2 dqn_vs_minimal_defense-v2


# V3 Experiments

tabular_q_learning_vs_random_defense-v3: training/v3/random_defense/tabular_q_learning/run.py training/v3/random_defense/tabular_q_learning/run.sh
	cd training/v3/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v3: training/v3/minimal_defense/tabular_q_learning/run.py training/v3/minimal_defense/tabular_q_learning/run.sh
	cd training/v3/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_fq_learning-v3: training/v3/random_attack/tabular_q_learning/run.py training/v3/random_attack/tabular_q_learning/run.sh
	cd training/v3/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v3: training/v3/maximal_attack/tabular_q_learning/run.py training/v3/maximal_attack/tabular_q_learning/run.sh
	cd training/v3/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v3: training/v3/two_agents/tabular_q_learning/run.py training/v3/two_agents/tabular_q_learning/run.sh
	cd training/v3/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_random_defense-v3: training/v3/random_defense/dqn/run.py training/v3/random_defense/dqn/run.sh
	cd training/v3/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v3: training/v3/minimal_defense/dqn/run.py training/v3/minimal_defense/dqn/run.sh
	cd training/v3/minimal_defense/dqn/ && $(MAKE) run

random_vs_random-v3: simulations/v3/random_vs_random/run.py simulations/v3/random_vs_random/run.sh
	cd simulations/v3/random_vs_random/ && $(MAKE) run

random_vs_defend_minimal-v3: simulations/v3/random_vs_defend_minimal/run.py simulations/v3/random_vs_defend_minimal/run.sh
	cd simulations/v3/random_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_defend_minimal-v3: simulations/v3/attack_maximal_vs_defend_minimal/run.py simulations/v3/attack_maximal_vs_defend_minimal/run.sh
	cd simulations/v3/attack_maximal_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_random-v3: simulations/v3/attack_maximal_vs_random/run.py simulations/v3/attack_maximal_vs_random/run.sh
	cd simulations/v3/attack_maximal_vs_random/ && $(MAKE) run

tabular_q_agent_vs_tabular_q_agent-v3: simulations/v3/tabular_q_agent_vs_tabular_q_agent/run.py simulations/v3/tabular_q_agent_vs_tabular_q_agent/run.sh
	cd simulations/v3/tabular_q_agent_vs_tabular_q_agent/ && $(MAKE) run

v3: tabular_q_learning_vs_random_defense-v3 tabular_q_learning_vs_minimal_defense-v3
v3: random_attack_vs_tabular_fq_learning-v3 maximal_attack_vs_tabular_q_learning-v3
v3: random_vs_random-v3 random_vs_defend_minimal-v3 attack_maximal_vs_defend_minimal-v3
v3: attack_maximal_vs_random-v3 tabular_q_learning_vs_tabular_q_learning-v3
v3: dqn_vs_random_defense-v3 tabular_q_agent_vs_tabular_q_agent-v3 dqn_vs_minimal_defense-v3

# V4 Experiments

tabular_q_learning_vs_random_defense-v4: training/v4/random_defense/tabular_q_learning/run.py training/v4/random_defense/tabular_q_learning/run.sh
	cd training/v4/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v4: training/v4/minimal_defense/tabular_q_learning/run.py training/v4/minimal_defense/tabular_q_learning/run.sh
	cd training/v4/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_fq_learning-v4: training/v4/random_attack/tabular_q_learning/run.py training/v4/random_attack/tabular_q_learning/run.sh
	cd training/v4/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v4: training/v4/maximal_attack/tabular_q_learning/run.py training/v4/maximal_attack/tabular_q_learning/run.sh
	cd training/v4/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v4: training/v4/two_agents/tabular_q_learning/run.py training/v4/two_agents/tabular_q_learning/run.sh
	cd training/v4/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_random_defense-v4: training/v4/random_defense/dqn/run.py training/v4/random_defense/dqn/run.sh
	cd training/v4/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v4: training/v4/minimal_defense/dqn/run.py training/v4/minimal_defense/dqn/run.sh
	cd training/v4/minimal_defense/dqn/ && $(MAKE) run

random_vs_random-v4: simulations/v4/random_vs_random/run.py simulations/v4/random_vs_random/run.sh
	cd simulations/v4/random_vs_random/ && $(MAKE) run

random_vs_defend_minimal-v4: simulations/v4/random_vs_defend_minimal/run.py simulations/v4/random_vs_defend_minimal/run.sh
	cd simulations/v4/random_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_defend_minimal-v4: simulations/v4/attack_maximal_vs_defend_minimal/run.py simulations/v4/attack_maximal_vs_defend_minimal/run.sh
	cd simulations/v4/attack_maximal_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_random-v4: simulations/v4/attack_maximal_vs_random/run.py simulations/v4/attack_maximal_vs_random/run.sh
	cd simulations/v4/attack_maximal_vs_random/ && $(MAKE) run

tabular_q_agent_vs_defend_minimal_sim-v4: simulations/v4/tabular_q_agent_vs_defend_minimal/run.py simulations/v4/tabular_q_agent_vs_defend_minimal/run.sh
	cd simulations/v4/tabular_q_agent_vs_defend_minimal/ && $(MAKE) run


v4: tabular_q_learning_vs_random_defense-v4 tabular_q_learning_vs_minimal_defense-v4
v4: random_attack_vs_tabular_fq_learning-v4 maximal_attack_vs_tabular_q_learning-v4
v4: random_vs_random-v4 random_vs_defend_minimal-v4 attack_maximal_vs_defend_minimal-v4
v4: attack_maximal_vs_random-v4 tabular_q_agent_vs_defend_minimal_sim-v4
v4: tabular_q_learning_vs_tabular_q_learning-v4 dqn_vs_random_defense-v4 dqn_vs_minimal_defense-v4

# V5 Experiments

tabular_q_learning_vs_random_defense-v5: training/v5/random_defense/tabular_q_learning/run.py training/v5/random_defense/tabular_q_learning/run.sh
	cd training/v5/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v5: training/v5/minimal_defense/tabular_q_learning/run.py training/v5/minimal_defense/tabular_q_learning/run.sh
	cd training/v5/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_fq_learning-v5: training/v5/random_attack/tabular_q_learning/run.py training/v5/random_attack/tabular_q_learning/run.sh
	cd training/v5/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v5: training/v5/maximal_attack/tabular_q_learning/run.py training/v5/maximal_attack/tabular_q_learning/run.sh
	cd training/v5/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v5: training/v5/two_agents/tabular_q_learning/run.py training/v5/two_agents/tabular_q_learning/run.sh
	cd training/v5/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_random_defense-v5: training/v5/random_defense/dqn/run.py training/v5/random_defense/dqn/run.sh
	cd training/v5/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v5: training/v5/minimal_defense/dqn/run.py training/v5/minimal_defense/dqn/run.sh
	cd training/v5/minimal_defense/dqn/ && $(MAKE) run

random_vs_random-v5: simulations/v5/random_vs_random/run.py simulations/v5/random_vs_random/run.sh
	cd simulations/v5/random_vs_random/ && $(MAKE) run

random_vs_defend_minimal-v5: simulations/v5/random_vs_defend_minimal/run.py simulations/v5/random_vs_defend_minimal/run.sh
	cd simulations/v5/random_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_defend_minimal-v5: simulations/v5/attack_maximal_vs_defend_minimal/run.py simulations/v5/attack_maximal_vs_defend_minimal/run.sh
	cd simulations/v5/attack_maximal_vs_defend_minimal/ && $(MAKE) run

attack_maximal_vs_random-v5: simulations/v4/attack_maximal_vs_random/run.py simulations/v5/attack_maximal_vs_random/run.sh
	cd simulations/v5/attack_maximal_vs_random/ && $(MAKE) run

v5: tabular_q_learning_vs_random_defense-v5 tabular_q_learning_vs_minimal_defense-v5
v5: random_attack_vs_tabular_fq_learning-v5 maximal_attack_vs_tabular_q_learning-v5
v5: random_vs_random-v5 random_vs_defend_minimal-v5 attack_maximal_vs_defend_minimal-v5
v5: attack_maximal_vs_random-v5 tabular_q_learning_vs_tabular_q_learning-v5
v5: dqn_vs_random_defense-v5 dqn_vs_minimal_defense-v5

# V6 Experiments

tabular_q_learning_vs_minimal_defense-v6: training/v6/minimal_defense/tabular_q_learning/run.py training/v6/minimal_defense/tabular_q_learning/run.sh
	cd training/v6/minimal_defense/tabular_q_learning/ && $(MAKE) run

dqn_vs_minimal_defense-v6: training/v6/minimal_defense/dqn/run.py training/v6/minimal_defense/dqn/run.sh
	cd training/v6/minimal_defense/dqn/ && $(MAKE) run

v6: tabular_q_learning_vs_minimal_defense-v6 dqn_vs_minimal_defense-v6

# V7 Experiments

tabular_q_learning_vs_random_defense-v7: training/v7/random_defense/tabular_q_learning/run.py training/v7/random_defense/tabular_q_learning/run.sh
	cd training/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v7: training/v7/minimal_defense/tabular_q_learning/run.py training/v7/minimal_defense/tabular_q_learning/run.sh
	cd training/v7/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_q_learning-v7: training/v7/random_attack/tabular_q_learning/run.py training/v7/random_attack/tabular_q_learning/run.sh
	cd training/v7/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v7: training/v7/maximal_attack/tabular_q_learning/run.py training/v7/maximal_attack/tabular_q_learning/run.sh
	cd training/v7/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v7: training/v7/two_agents/tabular_q_learning/run.py training/v7/two_agents/tabular_q_learning/run.sh
	cd training/v7/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_tabular_random_defense-v7: training/v7/random_defense/dqn/run.py training/v7/random_defense/dqn/run.sh
	cd training/v7/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v7: training/v7/minimal_defense/dqn/run.py training/v7/minimal_defense/dqn/run.sh
	cd training/v7/minimal_defense/dqn/ && $(MAKE) run

maximal_attack_vs_dqn-v7: training/v7/maximal_attack/dqn/run.py training/v7/maximal_attack/dqn/run.sh
	cd training/v7/maximal_attack/dqn/ && $(MAKE) run

random_attack_vs_dqn-v7: training/v7/random_attack/dqn/run.py training/v7/random_attack/dqn/run.sh
	cd training/v7/random_attack/dqn/ && $(MAKE) run

dqn_vs_dqn-v7: training/v7/two_agents/dqn/run.py training/v7/two_agents/dqn/run.sh
	cd training/v7/two_agents/dqn/ && $(MAKE) run

reinforce_vs_minimal_defense-v7: training/v7/minimal_defense/reinforce/run.py training/v7/minimal_defense/reinforce/run.sh
	cd training/v7/minimal_defense/reinforce/ && $(MAKE) run

reinforce_vs_random_defense-v7: training/v7/random_defense/reinforce/run.py training/v7/random_defense/reinforce/run.sh
	cd training/v7/random_defense/reinforce/ && $(MAKE) run

maximal_attack_vs_reinforce-v7: training/v7/maximal_attack/reinforce/run.py training/v7/maximal_attack/reinforce/run.sh
	cd training/v7/maximal_attack/reinforce/ && $(MAKE) run

random_attack_vs_reinforce-v7: training/v7/random_attack/reinforce/run.py training/v7/random_attack/reinforce/run.sh
	cd training/v7/random_attack/reinforce/ && $(MAKE) run

reinforce_vs_reinforce-v7: training/v7/two_agents/reinforce/run.py training/v7/two_agents/reinforce/run.sh
	cd training/v7/two_agents/reinforce/ && $(MAKE) run

actor_critic_vs_minimal_defense-v7: training/v7/minimal_defense/actor_critic/run.py training/v7/minimal_defense/actor_critic/run.sh
	cd training/v7/minimal_defense/actor_critic/ && $(MAKE) run

actor_critic_vs_random_defense-v7: training/v7/random_defense/actor_critic/run.py training/v7/random_defense/actor_critic/run.sh
	cd training/v7/random_defense/actor_critic/ && $(MAKE) run

maximal_attack_vs_actor_critic-v7: training/v7/maximal_attack/actor_critic/run.py training/v7/maximal_attack/actor_critic/run.sh
	cd training/v7/maximal_attack/actor_critic/ && $(MAKE) run

random_attack_vs_actor_critic-v7: training/v7/random_attack/actor_critic/run.py training/v7/random_attack/actor_critic/run.sh
	cd training/v7/random_attack/actor_critic/ && $(MAKE) run

actor_critic_vs_actor_critic-v7: training/v7/two_agents/actor_critic/run.py training/v7/two_agents/actor_critic/run.sh
	cd training/v7/two_agents/actor_critic/ && $(MAKE) run


v7: tabular_q_learning_vs_random_defense-v7 tabular_q_learning_vs_minimal_defense-v7 random_attack_vs_tabular_q_learning-v7
v7: maximal_attack_vs_tabular_q_learning-v7 tabular_q_learning_vs_tabular_q_learning-v7 dqn_vs_tabular_random_defense-v7
v7: dqn_vs_minimal_defense-v7 maximal_attack_vs_dqn-v7 random_attack_vs_dqn-v7 dqn_vs_dqn-v7
v7: reinforce_vs_minimal_defense-v7 reinforce_vs_random_defense-v7 maximal_attack_vs_reinforce-v7 random_attack_vs_reinforce-v7
v7: reinforce_vs_reinforce-v7 actor_critic_vs_minimal_defense-v7 actor_critic_vs_random_defense-v7 maximal_attack_vs_actor_critic-v7
v7: random_attack_vs_actor_critic-v7 actor_critic_vs_actor_critic-v7

# v8 Experiments

tabular_q_learning_vs_random_defense-v8: training/v8/random_defense/tabular_q_learning/run.py training/v8/random_defense/tabular_q_learning/run.sh
	cd training/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v8: training/v8/minimal_defense/tabular_q_learning/run.py training/v8/minimal_defense/tabular_q_learning/run.sh
	cd training/v8/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_q_learning-v8: training/v8/random_attack/tabular_q_learning/run.py training/v8/random_attack/tabular_q_learning/run.sh
	cd training/v8/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v8: training/v8/maximal_attack/tabular_q_learning/run.py training/v8/maximal_attack/tabular_q_learning/run.sh
	cd training/v8/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v8: training/v8/two_agents/tabular_q_learning/run.py training/v8/two_agents/tabular_q_learning/run.sh
	cd training/v8/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_random_defense-v8: training/v8/random_defense/dqn/run.py training/v8/random_defense/dqn/run.sh
	cd training/v8/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v8: training/v8/minimal_defense/dqn/run.py training/v8/minimal_defense/dqn/run.sh
	cd training/v8/minimal_defense/dqn/ && $(MAKE) run

maximal_attack_vs_dqn-v8: training/v8/maximal_attack/dqn/run.py training/v8/maximal_attack/dqn/run.sh
	cd training/v8/maximal_attack/dqn/ && $(MAKE) run

random_attack_vs_dqn-v8: training/v8/random_attack/dqn/run.py training/v8/random_attack/dqn/run.sh
	cd training/v8/random_attack/dqn/ && $(MAKE) run

dqn_vs_dqn-v8: training/v8/two_agents/dqn/run.py training/v8/two_agents/dqn/run.sh
	cd training/v8/two_agents/dqn/ && $(MAKE) run

reinforce_vs_minimal_defense-v8: training/v8/minimal_defense/reinforce/run.py training/v8/minimal_defense/reinforce/run.sh
	cd training/v8/minimal_defense/reinforce/ && $(MAKE) run

reinforce_vs_random_defense-v8: training/v8/random_defense/reinforce/run.py training/v8/random_defense/reinforce/run.sh
	cd training/v8/random_defense/reinforce/ && $(MAKE) run

maximal_attack_vs_reinforce-v8: training/v8/maximal_attack/reinforce/run.py training/v8/maximal_attack/reinforce/run.sh
	cd training/v8/maximal_attack/reinforce/ && $(MAKE) run

random_attack_vs_reinforce-v8: training/v8/random_attack/reinforce/run.py training/v8/random_attack/reinforce/run.sh
	cd training/v8/random_attack/reinforce/ && $(MAKE) run

reinforce_vs_reinforce-v8: training/v8/two_agents/reinforce/run.py training/v8/two_agents/reinforce/run.sh
	cd training/v8/two_agents/reinforce/ && $(MAKE) run

actor_critic_vs_minimal_defense-v8: training/v8/minimal_defense/actor_critic/run.py training/v8/minimal_defense/actor_critic/run.sh
	cd training/v8/minimal_defense/actor_critic/ && $(MAKE) run

actor_critic_vs_random_defense-v8: training/v8/random_defense/actor_critic/run.py training/v8/random_defense/actor_critic/run.sh
	cd training/v8/random_defense/actor_critic/ && $(MAKE) run

maximal_attack_vs_actor_critic-v8: training/v8/maximal_attack/actor_critic/run.py training/v8/maximal_attack/actor_critic/run.sh
	cd training/v8/maximal_attack/actor_critic/ && $(MAKE) run

random_attack_vs_actor_critic-v8: training/v8/random_attack/actor_critic/run.py training/v8/random_attack/actor_critic/run.sh
	cd training/v8/random_attack/actor_critic/ && $(MAKE) run

actor_critic_vs_actor_critic-v8: training/v8/two_agents/actor_critic/run.py training/v8/two_agents/actor_critic/run.sh
	cd training/v8/two_agents/actor_critic/ && $(MAKE) run


v8: tabular_q_learning_vs_random_defense-v8 tabular_q_learning_vs_minimal_defense-v8 random_attack_vs_tabular_q_learning-v8
v8: maximal_attack_vs_tabular_q_learning-v8 tabular_q_learning_vs_tabular_q_learning-v8 dqn_vs_random_defense-v8
v8: dqn_vs_minimal_defense-v8 maximal_attack_vs_dqn-v8 random_attack_vs_dqn-v8 dqn_vs_dqn-v8 reinforce_vs_minimal_defense-v8
v8: reinforce_vs_reinforce-v8 reinforce_vs_random_defense-v8 maximal_attack_vs_reinforce-v8 random_attack_vs_reinforce-v8
v8: actor_critic_vs_minimal_defense-v8 actor_critic_vs_random_defense-v8 maximal_attack_vs_actor_critic-v8
v8: random_attack_vs_actor_critic-v8 actor_critic_vs_actor_critic-v8


# v9 Experiments

tabular_q_learning_vs_random_defense-v9: training/v9/random_defense/tabular_q_learning/run.py training/v9/random_defense/tabular_q_learning/run.sh
	cd training/random_defense/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v9: training/v9/minimal_defense/tabular_q_learning/run.py training/v9/minimal_defense/tabular_q_learning/run.sh
	cd training/v9/minimal_defense/tabular_q_learning/ && $(MAKE) run

random_attack_vs_tabular_q_learning-v9: training/v9/random_attack/tabular_q_learning/run.py training/v9/random_attack/tabular_q_learning/run.sh
	cd training/v9/random_attack/tabular_q_learning/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v9: training/v9/maximal_attack/tabular_q_learning/run.py training/v9/maximal_attack/tabular_q_learning/run.sh
	cd training/v9/maximal_attack/tabular_q_learning/ && $(MAKE) run

tabular_q_learning_vs_tabular_q_learning-v9: training/v9/two_agents/tabular_q_learning/run.py training/v9/two_agents/tabular_q_learning/run.sh
	cd training/v9/two_agents/tabular_q_learning/ && $(MAKE) run

dqn_vs_tabular_random_defense-v9: training/v9/random_defense/dqn/run.py training/v9/random_defense/dqn/run.sh
	cd training/v9/random_defense/dqn/ && $(MAKE) run

dqn_vs_minimal_defense-v9: training/v9/minimal_defense/dqn/run.py training/v9/minimal_defense/dqn/run.sh
	cd training/v9/minimal_defense/dqn/ && $(MAKE) run

maximal_attack_vs_dqn-v9: training/v9/maximal_attack/dqn/run.py training/v9/maximal_attack/dqn/run.sh
	cd training/v9/maximal_attack/dqn/ && $(MAKE) run

random_attack_vs_dqn-v9: training/v9/random_attack/dqn/run.py training/v9/random_attack/dqn/run.sh
	cd training/v9/random_attack/dqn/ && $(MAKE) run

dqn_vs_dqn-v9: training/v9/two_agents/dqn/run.py training/v9/two_agents/dqn/run.sh
	cd training/v9/two_agents/dqn/ && $(MAKE) run

reinforce_vs_minimal_defense-v9: training/v9/minimal_defense/reinforce/run.py training/v9/minimal_defense/reinforce/run.sh
	cd training/v9/minimal_defense/reinforce/ && $(MAKE) run

reinforce_vs_random_defense-v9: training/v9/random_defense/reinforce/run.py training/v9/random_defense/reinforce/run.sh
	cd training/v9/random_defense/reinforce/ && $(MAKE) run

maximal_attack_vs_reinforce-v9: training/v9/maximal_attack/reinforce/run.py training/v9/maximal_attack/reinforce/run.sh
	cd training/v9/maximal_attack/reinforce/ && $(MAKE) run

random_attack_vs_reinforce-v9: training/v9/random_attack/reinforce/run.py training/v9/random_attack/reinforce/run.sh
	cd training/v9/random_attack/reinforce/ && $(MAKE) run

reinforce_vs_reinforce-v9: training/v9/two_agents/reinforce/run.py training/v9/two_agents/reinforce/run.sh
	cd training/v9/two_agents/reinforce/ && $(MAKE) run

actor_critic_vs_minimal_defense-v9: training/v9/minimal_defense/actor_critic/run.py training/v9/minimal_defense/actor_critic/run.sh
	cd training/v9/minimal_defense/actor_critic/ && $(MAKE) run

actor_critic_vs_random_defense-v9: training/v9/random_defense/actor_critic/run.py training/v9/random_defense/actor_critic/run.sh
	cd training/v9/random_defense/actor_critic/ && $(MAKE) run

maximal_attack_vs_actor_critic-v9: training/v9/maximal_attack/actor_critic/run.py training/v9/maximal_attack/actor_critic/run.sh
	cd training/v9/maximal_attack/actor_critic/ && $(MAKE) run

random_attack_vs_actor_critic-v9: training/v9/random_attack/actor_critic/run.py training/v9/random_attack/actor_critic/run.sh
	cd training/v9/random_attack/actor_critic/ && $(MAKE) run

actor_critic_vs_actor_critic-v9: training/v9/two_agents/actor_critic/run.py training/v9/two_agents/actor_critic/run.sh
	cd training/v9/two_agents/actor_critic/ && $(MAKE) run

v9: tabular_q_learning_vs_random_defense-v9 tabular_q_learning_vs_minimal_defense-v9 random_attack_vs_tabular_q_learning-v9
v9: maximal_attack_vs_tabular_q_learning-v9 tabular_q_learning_vs_tabular_q_learning-v9 dqn_vs_tabular_random_defense-v9
v9: dqn_vs_minimal_defense-v9 maximal_attack_vs_dqn-v9 random_attack_vs_dqn-v9 dqn_vs_dqn-v9
v9: reinforce_vs_minimal_defense-v9 reinforce_vs_random_defense-v9 maximal_attack_vs_reinforce-v9 random_attack_vs_reinforce-v9
v9: reinforce_vs_reinforce-v9 actor_critic_vs_minimal_defense-v9 actor_critic_vs_random_defense-v9 maximal_attack_vs_actor_critic-v9
v9: random_attack_vs_actor_critic-v9 actor_critic_vs_actor_critic-v9

# v10 Experiments

actor_critic_vs_minimal_defense-v10: training/v10/minimal_defense/actor_critic/run.py training/v10/minimal_defense/actor_critic/run.sh
	cd training/v10/minimal_defense/actor_critic/ && $(MAKE) run

actor_critic_vs_actor_critic-v10: training/v10/two_agents/actor_critic/run.py training/v10/two_agents/actor_critic/run.sh
	cd training/v10/two_agents/actor_critic/ && $(MAKE) run

v10: actor_critic_vs_minimal_defense-v10 actor_critic_vs_actor_critic-v10

# v11 Experiments

actor_critic_vs_minimal_defense-v11: training/v11/minimal_defense/actor_critic/run.py training/v11/minimal_defense/actor_critic/run.sh
	cd training/v11/minimal_defense/actor_critic/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v11: training/v11/minimal_defense/tabular_q_learning/run.py training/v11/minimal_defense/tabular_q_learning/run.sh
	cd training/v11/minimal_defense/tabular_q_learning/ && $(MAKE) run

actor_critic_vs_actor_critic-v11: training/v11/two_agents/actor_critic/run.py training/v11/two_agents/actor_critic/run.sh
	cd training/v11/two_agents/actor_critic/ && $(MAKE) run

v11: actor_critic_vs_minimal_defense-v11 actor_critic_vs_actor_critic-v11 tabular_q_learning_vs_minimal_defense-v11

# v12 Experiments

actor_critic_vs_minimal_defense-v12: training/v12/minimal_defense/actor_critic/run.py training/v12/minimal_defense/actor_critic/run.sh
	cd training/v12/minimal_defense/actor_critic/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v12: training/v12/minimal_defense/tabular_q_learning/run.py training/v12/minimal_defense/tabular_q_learning/run.sh
	cd training/v12/minimal_defense/tabular_q_learning/ && $(MAKE) run

actor_critic_vs_actor_critic-v12: training/v12/two_agents/actor_critic/run.py training/v12/two_agents/actor_critic/run.sh
	cd training/v12/two_agents/actor_critic/ && $(MAKE) run

v12: actor_critic_vs_minimal_defense-v12 actor_critic_vs_actor_critic-v12 tabular_q_learning_vs_minimal_defense-v12

# v13 Experiments

actor_critic_vs_minimal_defense-v13: training/v13/minimal_defense/actor_critic/run.py training/v13/minimal_defense/actor_critic/run.sh
	cd training/v13/minimal_defense/actor_critic/ && $(MAKE) run

tabular_q_learning_vs_minimal_defense-v13: training/v13/minimal_defense/tabular_q_learning/run.py training/v13/minimal_defense/tabular_q_learning/run.sh
	cd training/v13/minimal_defense/tabular_q_learning/ && $(MAKE) run

actor_critic_vs_actor_critic-v13: training/v13/two_agents/actor_critic/run.py training/v13/two_agents/actor_critic/run.sh
	cd training/v13/two_agents/actor_critic/ && $(MAKE) run

maximal_attack_vs_tabular_q_learning-v13: training/v13/maximal_attack/tabular_q_learning/run.py training/v13/maximal_attack/tabular_q_learning/run.sh
	cd training/v13/maximal_attack/tabular_q_learnig/ && $(MAKE) run

v13: actor_critic_vs_minimal_defense-v13 actor_critic_vs_actor_critic-v13 tabular_q_learning_vs_minimal_defense-v13
v13: maximal_attack_vs_tabular_q_learning-v13

# v14 Experiments

actor_critic_vs_minimal_defense-v14: training/v14/minimal_defense/actor_critic/run.py training/v14/minimal_defense/actor_critic/run.sh
	cd training/v14/minimal_defense/actor_critic/ && $(MAKE) run

ppo_vs_minimal_defense-v14: training/v14/minimal_defense/ppo/run.py training/v14/minimal_defense/ppo/run.sh
	cd training/v14/minimal_defense/ppo/ && $(MAKE) run

reinforce_vs_minimal_defense-v14: training/v14/minimal_defense/reinforce/run.py training/v14/minimal_defense/reinforce/run.sh
	cd training/v14/minimal_defense/reinforce/ && $(MAKE) run

reinforce_vs_random_defense-v14: training/v14/random_defense/actor_critic/run.py training/v14/random_defense/actor_critic/run.sh
	cd training/v14/random_defense/actor_critic/ && $(MAKE) run

reinforce_vs_reinforce-v14: training/v14/two_agents/reinforce/run.py training/v14/two_agents/reinforce/run.sh
	cd training/v14/two_agents/reinforce/ && $(MAKE) run

v14: reinforce_vs_reinforce-v14 reinforce_vs_random_defense-v14 reinforce_vs_minimal_defense-v14
v14: ppo_vs_minimal_defense-v14 actor_critic_vs_minimal_defense-v14

# v15 Experiments

reinforce_vs_minimal_defense-v15: training/v15/minimal_defense/reinforce/run.py training/v15/minimal_defense/reinforce/run.sh
	cd training/v15/minimal_defense/reinforce/ && $(MAKE) run

v15: reinforce_vs_minimal_defense-v15

# v16 Experiments

ppo_openai_vs_minimal_defense-v16: training/v16/minimal_defense/ppo_openai/run.py training/v16/minimal_defense/ppo_openai/run.sh
	cd training/v16/minimal_defense/ppo_openai/ && $(MAKE) run

reinforce_vs_minimal_defense-v16: training/v16/minimal_defense/reinforce/run.py training/v16/minimal_defense/reinforce/run.sh
	cd training/v16/minimal_defense/reinforce/ && $(MAKE) run

reinforce_vs_random_defense-v16: training/v16/random_defense/reinforce/run.py training/v16/random_defense/reinforce/run.sh
	cd training/v16/random_defense/reinforce/ && $(MAKE) run

reinforce_vs_reinforce-v16: training/v16/two_agents/reinforce/run.py training/v16/two_agents/reinforce/run.sh
	cd training/v16/two_agents/reinforce/ && $(MAKE) run

ppo_openai_vs_ppo_openai-v16: training/v16/two_agents/ppo_openai/run.py training/v16/two_agents/ppo_openai/run.sh
	cd training/v16/two_agents/ppo_openai/ && $(MAKE) run

maximal_attack_vs_ppo_openai-v16: training/v16/maximal_attack/ppo_openai/run.py training/v16/maximal_attack/ppo_openai/run.sh
	cd training/v16/maximal_attack/ppo_openai/ && $(MAKE) run

maximal_attack_vs_reinforce-v16: training/v16/maximal_attack/reinforce/run.py training/v16/maximal_attack/reinforce/run.sh
	cd training/v16/maximal_attack/reinforce/ && $(MAKE) run

v16: ppo_openai_vs_minimal_defense-v16 reinforce_vs_minimal_defense-v16 reinforce_vs_random_defense-v16
v16: reinforce_vs_reinforce-v16 maximal_attack_vs_ppo_openai-v16 maximal_attack_vs_reinforce-v16
v16: ppo_openai_vs_ppo_openai-v16

# v17 Experiments

ppo_openai_vs_minimal_defense-v17: training/v17/minimal_defense/ppo_openai/run.py training/v17/minimal_defense/ppo_openai/run.sh
	cd training/v17/minimal_defense/ppo_openai/ && $(MAKE) run

reinforce_vs_minimal_defense-v17: training/v17/minimal_defense/reinforce/run.py training/v17/minimal_defense/reinforce/run.sh
	cd training/v17/minimal_defense/reinforce/ && $(MAKE) run

reinforce_vs_random_defense-v17: training/v17/random_defense/reinforce/run.py training/v17/random_defense/reinforce/run.sh
	cd training/v17/random_defense/reinforce/ && $(MAKE) run

reinforce_vs_reinforce-v17: training/v17/two_agents/reinforce/run.py training/v17/two_agents/reinforce/run.sh
	cd training/v17/two_agents/reinforce/ && $(MAKE) run

ppo_openai_vs_ppo_openai-v17: training/v17/two_agents/ppo_openai/run.py training/v17/two_agents/ppo_openai/run.sh
	cd training/v17/two_agents/ppo_openai/ && $(MAKE) run

maximal_attack_vs_ppo_openai-v17: training/v17/maximal_attack/ppo_openai/run.py training/v17/maximal_attack/ppo_openai/run.sh
	cd training/v17/maximal_attack/ppo_openai/ && $(MAKE) run

maximal_attack_vs_reinforce-v17: training/v17/maximal_attack/reinforce/run.py training/v17/maximal_attack/reinforce/run.sh
	cd training/v17/maximal_attack/reinforce/ && $(MAKE) run

v17: ppo_openai_vs_minimal_defense-v17 reinforce_vs_minimal_defense-v17 reinforce_vs_random_defense-v17
v17: reinforce_vs_reinforce-v17 maximal_attack_vs_ppo_openai-v17 maximal_attack_vs_reinforce-v17
v17: ppo_openai_vs_ppo_openai-v17

# Tests

tests: it_tests/run.py it_tests/run.sh
	cd it_tests/ && $(MAKE) run

# All

all: v0 v1 v2 v3 v4 v5 v6 v7 v8 v9 v10 v11 v12 v13 v14 v15 v16 v17 tests

# Clean

clean:

	# V0
	cd ./training/v0/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v0/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v0/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v0/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v0/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v0/random_attack/dqn/ && $(MAKE) clean
	cd ./training/v0/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v0/maximal_attack/dqn/ && $(MAKE) clean
	cd ./training/v0/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd simulations/v0/random_vs_random/ && $(MAKE) clean
	cd simulations/v0/random_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v0/attack_maximal_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v0/attack_maximal_vs_random/ && $(MAKE) clean
	cd simulations/v0/tabular_q_agent_vs_random/ && $(MAKE) clean
	cd simulations/v0/random_vs_tabular_q_agent/ && $(MAKE) clean

	# V1
	cd ./training/v1/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v1/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v1/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v1/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v1/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v1/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v1/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd simulations/v1/random_vs_random/ && $(MAKE) clean
	cd simulations/v1/random_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v1/attack_maximal_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v1/attack_maximal_vs_random/ && $(MAKE) clean

	# V2
	cd ./training/v2/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v2/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v2/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v2/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v2/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v2/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v2/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd simulations/v2/random_vs_random/ && $(MAKE) clean
	cd simulations/v2/random_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v2/attack_maximal_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v2/attack_maximal_vs_random/ && $(MAKE) clean

	# V3
	cd ./training/v3/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v3/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v3/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v3/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v3/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v3/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v3/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd simulations/v3/random_vs_random/ && $(MAKE) clean
	cd simulations/v3/random_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v3/attack_maximal_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v3/attack_maximal_vs_random/ && $(MAKE) clean
	cd simulations/v3/tabular_q_agent_vs_tabular_q_agent/ && $(MAKE) clean

	# V4
	cd ./training/v4/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v4/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v4/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v4/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v4/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v4/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v4/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd simulations/v4/random_vs_random/ && $(MAKE) clean
	cd simulations/v4/random_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v4/attack_maximal_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v4/attack_maximal_vs_random/ && $(MAKE) clean
	cd simulations/v4/tabular_q_agent_vs_defend_minimal/ && $(MAKE) clean

	# V5
	cd ./training/v5/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v5/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v5/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v5/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v5/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v5/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v5/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd simulations/v5/random_vs_random/ && $(MAKE) clean
	cd simulations/v5/random_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v5/attack_maximal_vs_defend_minimal/ && $(MAKE) clean
	cd simulations/v5/attack_maximal_vs_random/ && $(MAKE) clean

	# V6
	cd ./training/v6/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v6/minimal_defense/dqn/ && $(MAKE) clean

	# V7
	cd ./training/v7/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v7/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v7/random_defense/reinforce/ && $(MAKE) clean
	cd ./training/v7/random_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v7/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v7/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v7/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v7/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v7/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v7/random_attack/dqn/ && $(MAKE) clean
	cd ./training/v7/random_attack/reinforce/ && $(MAKE) clean
	cd ./training/v7/random_attack/actor_critic/ && $(MAKE) clean
	cd ./training/v7/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v7/maximal_attack/dqn/ && $(MAKE) clean
	cd ./training/v7/maximal_attack/actor_critic/ && $(MAKE) clean
	cd ./training/v7/maximal_attack/reinforce/ && $(MAKE) clean
	cd ./training/v7/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v7/two_agents/dqn/ && $(MAKE) clean
	cd ./training/v7/two_agents/reinforce/ && $(MAKE) clean
	cd ./training/v7/two_agents/actor_critic/ && $(MAKE) clean

	# V8
	cd ./training/v8/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v8/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v8/random_defense/reinforce/ && $(MAKE) clean
	cd ./training/v8/random_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v8/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v8/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v8/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v8/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v8/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v8/random_attack/dqn/ && $(MAKE) clean
	cd ./training/v8/random_attack/reinforce/ && $(MAKE) clean
	cd ./training/v8/random_attack/actor_critic/ && $(MAKE) clean
	cd ./training/v8/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v8/maximal_attack/dqn/ && $(MAKE) clean
	cd ./training/v8/maximal_attack/reinforce/ && $(MAKE) clean
	cd ./training/v8/maximal_attack/actor_critic/ && $(MAKE) clean
	cd ./training/v8/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v8/two_agents/dqn/ && $(MAKE) clean
	cd ./training/v8/two_agents/reinforce/ && $(MAKE) clean
	cd ./training/v8/two_agents/actor_critic/ && $(MAKE) clean

	# V9
	cd ./training/v9/random_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v9/random_defense/dqn/ && $(MAKE) clean
	cd ./training/v9/random_defense/reinforce/ && $(MAKE) clean
	cd ./training/v9/random_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v9/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v9/minimal_defense/dqn/ && $(MAKE) clean
	cd ./training/v9/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v9/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v9/random_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v9/random_attack/dqn/ && $(MAKE) clean
	cd ./training/v9/random_attack/reinforce/ && $(MAKE) clean
	cd ./training/v9/random_attack/actor_critic/ && $(MAKE) clean
	cd ./training/v9/maximal_attack/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v9/maximal_attack/dqn/ && $(MAKE) clean
	cd ./training/v9/maximal_attack/reinforce/ && $(MAKE) clean
	cd ./training/v9/maximal_attack/actor_critic/ && $(MAKE) clean
	cd ./training/v9/two_agents/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v9/two_agents/dqn/ && $(MAKE) clean
	cd ./training/v9/two_agents/reinforce/ && $(MAKE) clean
	cd ./training/v9/two_agents/actor_critic/ && $(MAKE) clean

	# V10
	cd ./training/v10/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v10/two_agents/actor_critic/ && $(MAKE) clean

	# V11
	cd ./training/v11/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v11/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v11/two_agents/actor_critic/ && $(MAKE) clean

	# V12
	cd ./training/v12/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v12/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v12/two_agents/actor_critic/ && $(MAKE) clean

	# V13
	cd ./training/v13/minimal_defense/tabular_q_learning/ && $(MAKE) clean
	cd ./training/v13/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v13/two_agents/actor_critic/ && $(MAKE) clean
	cd ./training/v13/maximal_attack/tabular_q_learning/ && $(MAKE) clean

	# V14
	cd ./training/v14/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v14/minimal_defense/actor_critic/ && $(MAKE) clean
	cd ./training/v14/minimal_defense/ppo/ && $(MAKE) clean
	cd ./training/v14/random_defense/reinforce/ && $(MAKE) clean
	cd ./training/v14/two_agents/reinforce/ && $(MAKE) clean

	# V15
	cd ./training/v15/minimal_defense/reinforce/ && $(MAKE) clean

	# V16
	cd ./training/v16/minimal_defense/ppo_openai/ && $(MAKE) clean
	cd ./training/v16/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v16/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v16/random_defense/reinforce/ && $(MAKE) clean
	cd ./training/v16/two_agents/reinforce/ && $(MAKE) clean
	cd ./training/v16/two_agents/ppo_openai/ && $(MAKE) clean
	cd ./training/v16/maximal_attack/ppo_openai/ && $(MAKE) clean
	cd ./training/v16/maximal_attack/reinforce/ && $(MAKE) clean

	# V17
	cd ./training/v17/minimal_defense/ppo_openai/ && $(MAKE) clean
	cd ./training/v17/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v17/minimal_defense/reinforce/ && $(MAKE) clean
	cd ./training/v17/random_defense/reinforce/ && $(MAKE) clean
	cd ./training/v17/two_agents/reinforce/ && $(MAKE) clean
	cd ./training/v17/two_agents/ppo_openai/ && $(MAKE) clean
	cd ./training/v17/maximal_attack/ppo_openai/ && $(MAKE) clean
	cd ./training/v17/maximal_attack/reinforce/ && $(MAKE) clean

	# Tests
	cd ./it_tests/ && $(MAKE) clean